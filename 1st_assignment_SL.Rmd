---
title: "Part 1: Statistical Tools"
author: "Ignacio AlmodÃ³var"
date: "12/11/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r,echo=FALSE}
library(dplyr)
library(caret)
library(ggplot2)
library(klaR)
library(GGally)
library(tidyverse)
library(MASS)
library(caret)
library(VGAM)
library(e1071)
library(ROSE)
```

# Download Data

The data chosen for this study has been taken from kaggle. It contains several financial ratios from companies and a column that specifies if the company is in bankruptcy or not.

The data were collected from the Taiwan Economic Journal for the years 1999 to 2009. Company bankruptcy was defined based on the business regulations of the Taiwan Stock Exchange.

```{r}
setwd("/Users/ignacioalmodovarcardenas/Desktop/Statistical Learning/Statistical_Learning/")
data=read.csv("data.csv")
data$Bankrupt.=as.factor(data$Bankrupt.)
data$Liability.Assets.Flag=as.factor(data$Liability.Assets.Flag)
dim(data)
```

We can see that there are 96 different variables. Working with this amount of variables is going to be practically impossible both in terms of understanding of the data set and about computation times. Therefore, I made a brief study about finance and found out which ratios are more useful to find whereas a company is in bankruptcy or not.

- Bankrupt: Binary class, 1 for bankruptcy 0 for not.
- ROAC: Return on total assets before interest and depreciation.
- Effective Tax Rate
- Total debt/Total net worth
- Debt ratio %: Liability/Total Assets
- Operating profit/Paid-in capital
- Cash/Total Assets
- Cash Flow to Equity
- Liability-Assets Flag: 1 if Total Liability exceeds Total Assets, 0 otherwise

```{r,echo=FALSE}
data_1 = data %>% dplyr::select(c(1,2,16,38,43,58,84,86))
names(data_1)
```

# Pre-process and Analyze

First of all I wanted to check if there are any missing values NA in my data set. In order to do that I wrote a function that specifies if there are any missing values, and if so, it says the number of missing values and the column that contains it.

```{r}
missingValues=function(data){
  count=0
  a=cbind(lapply(lapply(data, is.na), sum))
  for(i in 1:ncol(data)){
    if(a[i]!=0){
      cat("There are", a[i], "missing values in column ", i,"\n" )
      count=count+1
    }
  }  
    if(count==0){
      cat("There are No missing values in this dataset")
    }
}

missingValues(data)
```

Also, part of the pre-process we are going to split the dataset in training and testing sets.

```{r}
set.seed(1234)
index1=createDataPartition(y = data_1$Bankrupt.,p=0.6,list = FALSE)
trainSet=data_1[index1,]
testSet=data_1[-index1,]
```

Now, looking for differentiation in groups and other characteristics I am going to look for more information about which variables are the best predictors.

Therefore we are mainly going to use density plot in order to know if the variables might me good for prediction or not.

```{r}
trainSet %>% ggplot(aes(x =ROA.C..before.interest.and.depreciation.before.interest)) +  
  geom_density(aes( colour = Bankrupt., fill = Bankrupt.),alpha = 0.2)
```

We can see that using ROAC there is a slight difference on the two populations (Bankcruptcy o not), so we might use this variable for our prediction model.

```{r}
trainSet %>% ggplot(aes(x =Cash.Flow.to.Equity)) +  
  geom_density(aes( colour = Bankrupt., fill = Bankrupt.),alpha = 0.2)
```

Using this same process we can conclude that this variable is not going to be a god predictor by herself for our model, as both populations behaviors are quite similar.

```{r}
trainSet %>% ggplot(aes(x =Debt.ratio..)) +  
  geom_density(aes( colour = Bankrupt., fill = Bankrupt.),alpha = 0.2)

trainSet %>% ggplot(aes(x =Cash.Total.Assets)) +  
  geom_density(aes( colour = Bankrupt., fill = Bankrupt.),alpha = 0.2)

trainSet %>% ggplot(aes(x =Operating.profit.Paid.in.capital)) +  
  geom_density(aes( colour = Bankrupt., fill = Bankrupt.),alpha = 0.2)

trainSet %>% ggplot(aes(x =Tax.rate..A.)) +  
  geom_density(aes( colour = Bankrupt., fill = Bankrupt.),alpha = 0.2)

```
Within all this plots we can also say that the variable "Debt.ratio" can also be a good predictor for companies in bankruptcy.

In order to compare binary variables I decided to do barplots.

```{r}
ggplot(trainSet,aes(x=Liability.Assets.Flag,color=Bankrupt.,fill=Bankrupt.)) + geom_bar(size=2)
```

Within this plot you can see that the variable "Liability.Assets.Flag", is a good predictor for companies that are in Bankruptcy, as all of them have this flag, whereas only a few percentage of them that are not in Bankruptcy have this flag.

However, one of the problems in this dataset is that our target variable Bankruptcy is not so well balanced, as the number of observations in bankruptcy is way lower than the ones that are not. 

```{r}
as.integer(table(trainSet$Bankrupt.)[2])/as.integer(table(trainSet$Bankrupt.)[1])*100
```

We can see that only a 3.3% of the observations are in bankruptcy. As it is quite useless to make predictive models with datasets too unbalanced, we are going to make our training data balanced.

```{r}
data_balanced_train <- ovun.sample(Bankrupt. ~ ., data = trainSet, method = "over",N = 6092)$data
table(data_balanced_train$Bankrupt.)
```

Now let's create again a train and a control set.

```{r}
index2=createDataPartition(y = data_balanced_train$Bankrupt.,p=0.8,list = FALSE)
trainSet2=data_balanced_train[index2,]
testSet2=data_balanced_train[-index2,]
```

It is also very useful to do some boxplots in order to see if our data has large number of outliers or not.

```{r}
ggplot(trainSet2,aes(x=Bankrupt.,
                y = ROA.C..before.interest.and.depreciation.before.interest)) + 
  geom_boxplot()
```

As it can be seen there are a few of them, therefore we are going to save an index of outliers just in case I need to remove it in any case of the analysis.

```{r}
outliers <- boxplot(trainSet2$ROA.C..before.interest.and.depreciation.before.interest,
                    plot=FALSE)$out
```

Another way to find which variables might be good predictors we can use pairs and see the correlation between the different groups.

```{r}
pairs(trainSet2[,2:7],pch=21,col=c("blue","orange2")[trainSet2$Bankrupt.])
```

As it can be seen, most of the variables do split the observations in two groups. Even though there is no linear relationship between any of them, all of them differentiates the bankruptcy observations in one extreme of the scatter plot. Indeed we still can see that the best continuous predictors are the variables ROAC and Debt.ratio.

Other useful plots to visualize classification are the ones given by QDA and LDA

```{r}
partimat(Bankrupt. ~ Debt.ratio.. + ROA.C..before.interest.and.depreciation.before.interest + 
           Cash.Total.Assets ,data=trainSet2,method="lda",)
```
```{r}
partimat(Bankrupt. ~ Debt.ratio.. + ROA.C..before.interest.and.depreciation.before.interest + 
           Cash.Total.Assets ,data=trainSet2,method="qda",)
```

# Classification modeling

As our target is a binary variable, we are going to first start building our model by using Logistic Regression.

```{r}
log.fit = vglm(Bankrupt. ~ Debt.ratio.., family=multinomial(refLevel=1), data=trainSet2)
prob.test = predict(log.fit, newdata=testSet2, type="response")
pred.test <- as.factor(levels(testSet2$Bankrupt.)[max.col(prob.test)])
ConfMat = table(pred.test,testSet2$Bankrupt.)
ConfMat

n = length(testSet2$Bankrupt.)
prop.errors <- (n - sum(diag(ConfMat))) / n
prop.errors

accuracy <- sum(diag(ConfMat)) / n
accuracy
```

Building our logistic model with just one of our variables already gives a pretty good accuracy rate. However, the error is still quite high. We have to try to make the model being able to predict more companies that are in bankruptcy as it.

As the results obtained are promising, I am going to carry on the modeling using logistic regression, but now using all the variables in our training set.

```{r}
log.fit = vglm(Bankrupt. ~ ., family=multinomial(refLevel=1), data=trainSet2)
prob.test = predict(log.fit, newdata=testSet2, type="response")
pred.test <- as.factor(levels(testSet2$Bankrupt.)[max.col(prob.test)])
confusionMatrix(pred.test,testSet2$Bankrupt.)
```

The model obtained is actually pretty good already, both Kappa and Accuracy indicators have a good rate.

Now, let's try using the functions included in the library CARET. We can use a cross validation algorithm to improve our prediction. In addition, as we want to improve the kappa and not the accuracy due to the fact that our data is not perfectly balanced, we can specify it in the metric.

```{r}
ctrl <- trainControl(method = "repeatedcv", repeats = 4,number = 7)
lrFit <- train(Bankrupt. ~ ., 
                method = "glmnet",
                family = "binomial",
                data = testSet2,
                preProcess = c("center","scale"),
                tuneGrid = expand.grid(alpha = seq(0, 2, 0.1), lambda = seq(0, .1, 0.01)),
                metric = "Kappa",
                trControl = ctrl)
```


```{r}
lrPred = predict(lrFit, testSet2)
confusionMatrix(lrPred, testSet2$Bankrupt.)
```

As you can see, the prediction model obtained is very promising and behaves quite good. Nevertheless we are now going to build other models with different methods seen in class to see if we can also build good predictions with them.

First of all we are going to use LDA.

```{r}
lda.model <- lda(Bankrupt. ~ ., data=trainSet2,prior=c(0.5,0.5))
probability = predict(lda.model, newdata=testSet2)$posterior
prediction = predict(lda.model, newdata=testSet2)$class
confusionMatrix(prediction, testSet2$Bankrupt.)
```

Actually the accuracy obtained is quite surprising. Nevertheless we can see that again, the kappa is quite low and it directly affects to the amount of companies in bankruptcy predicted.

Trying with caret and using the cross validation method the model might improve.

```{r}
ldaFit <- train(Bankrupt. ~ ., 
                method = "lda", 
                data = trainSet2,
                preProcess = c("center", "scale"),
                metric = "Accuracy",
                trControl = ctrl)

ldaPred = predict(ldaFit, testSet2)
confusionMatrix(ldaPred,testSet2$Bankrupt.)
```

Surprisingly, this model is the best one so far, as it has both accuracy and kappa rates slightly higher than the ones obtained with the logistic regression.

Now, let's try with QDA

```{r}
qda.model <- qda(Bankrupt. ~ ., data=trainSet2,prior=c(0.5,0.5))
prediction = predict(qda.model, newdata=testSet2)$class
confusionMatrix(prediction, testSet2$Bankrupt.)
```

Using caret:

```{r,eval=FALSE}
#QDA using CARET
qdaFit <- train(Bankrupt. ~ ., 
                method = "qda", 
                data = trainSet2,
                preProcess = c("center", "scale"),
                metric = "Accuracy",
                trControl = ctrl)
```


```{r}
qdaPred = predict(qdaFit, testSet2)
confusionMatrix(qdaPred,testSet2$Bankrupt.)
```

The results obtained are not bad at all, however, I have been obtaining better predictions with the models used before. Therefore, we can conclude that QDA is not a good method to predict for this dataset.

Finally, let's try with Naive Bayes.

```{r}
naive.model <- naiveBayes(Bankrupt. ~ ., data=trainSet2, laplace=1, prior = c(0.5,0.5))
prediction = predict(naive.model, newdata=testSet2)
confusionMatrix(prediction, testSet2$Bankrupt.)
```

And using caret:

```{r,eval=FALSE}
nbFit <- train(Bankrupt. ~ ., 
                method = "nb", 
                data = trainSet2,
                preProcess = c("center", "scale"),
                metric = "Accuracy",
                trControl = ctrl)
```

```{r}
nbPred = predict(nbFit, testSet2)
confusionMatrix(nbPred, testSet2$Bankrupt.)
```

Again, the results obtained are pretty good, but we have already obtained better results both with LDA and logistic regression.

I have already built several models and even thoug each of them had their pros and cons, I'm going to stick with the one built using LDA in caret.

```{r}
confusionMatrix(ldaPred,testSet2$Bankrupt.)
```

Nevertheless, there is still a fact that bothers me in this model. It is the fact that the error rate for predicting companies in Bankruptcy is still quite high. From an investor point of view, this model will be quite useless, as it is predicting companies that are actually in bankruptcy wrong. Therefore, I need to upgrade this model in that aspect. This can be done changing the threshold that acts like a boundary for errors.

```{r}
lrProb = predict(ldaFit, newdata=testSet2, type="prob")
threshold = 0.4
lrPred = rep("0", nrow(testSet2))
lrPred[which(lrProb[,2] > threshold)] = "1"
lrPred = factor(lrPred)
confusionMatrix(lrPred, testSet2$Bankrupt.)
```

As it can bee seen, for the same model we get different results as the threshold moves. Now in order to find an optimal threshold we can run this code.

```{r}
relative.cost <- c(1, 2, 0.5, 0.0)
CM = confusionMatrix(lrPred, testSet2$Bankrupt.)$table
sum(relative.cost*CM)
cost.i = matrix(NA, nrow = 10, ncol = 9)

j <- 0


for (threshold in seq(0.35,0.75,0.05)){

  j <- j + 1

  for(i in 1:10){

    # partition data intro training (80%) and testing sets (20%)
    d <- createDataPartition(trainSet2$Bankrupt., p = 0.8, list = FALSE)
    
    train<-trainSet2[d,]
    test <-trainSet2[-d,]  
    
    ldaFit <- train(Bankrupt. ~ ., 
                    method = "lda", 
                    data = train,
                    preProcess = c("center", "scale"),
                    metric = "Accuracy",
                    trControl = ctrl)
    lrProb = predict(ldaFit, test, type="prob")
    
    lrPred = rep(0, nrow(test))
    lrPred[which(lrProb[,2] > threshold)] = 1
    lrPred = factor(lrPred)
    
    CM = confusionMatrix(lrPred, test$Bankrupt.)$table
    
    cost.i[i,j] <- sum(relative.cost*CM)/nrow(test) # unitary cost

    
  }
}

boxplot(cost.i, main = "Hyper-parameter selection",
        ylab = "cost",
        xlab = "threshold value",names = seq(0.35,0.75,0.05),col="lightblue")
```
From our point of view, as we are looking for having less error in the prediction of Bankruptcy companies, our optimal threshold is 0.35. If we wanted to get lower error on predicting companies that are not in Bankruptcy we will probably choose a threshold around 0.5 and 0.55.

Within this we can finally build our best model.

```{r}
# optimal threshold
threshold = 0.35

# final prediction
ldaFit <- train(Bankrupt. ~ ., 
                method = "sparseLDA", 
                data = trainSet2,
                preProcess = c("center", "scale"),
                metric = "Accuracy",
                trControl = ctrl)
ldaPred = predict(ldaFit, testSet2)

lrProb = predict(ldaFit, newdata=testSet2, type="prob")
lrPred = rep(0, nrow(testSet2))
lrPred[which(lrProb[,2] > threshold)] = 1
lrPred = factor(lrPred)
confusionMatrix(lrPred,testSet2$Bankrupt.)
```

# Conclusions

Working with this dataset has not been an easy thing. There were a few things that made it difficult and the main one was the fact that our target variable was Imbalanced, and not just a little bit. In this case the proportion was 97% of observations that were not in bankruptcy whereas only a 3% of them actually were.

When I first started working on the dataset (mainly in prepossess), I did not really know much about classification, therefore I didn't thought that it was going to be a problem having this difference in proportions. Later, when I started working on the predictive models I realized that the dataset was not being very useful, due the fact that on every model the accuracy was over 0.96, as most of the observations were predicting as not being in bankruptcy and only a few of them were (between 6 and 9 observations). 

As I have already worked a lot in this dataset, I could not start over with another different dataset so I focused my models on being able to get higher kappa, sensitivity, specificity and precision rates instead of focusing in the accuracy, which I really did not care about. 

Then looking through different resources I found our about different methods to balance the data, and I apply them to this dataset, what brought me the possibility to build good classification models.

